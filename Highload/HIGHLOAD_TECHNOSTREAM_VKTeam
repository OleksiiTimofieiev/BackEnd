https://www.youtube.com/watch?v=_d38g1tpLd8&list=PLrCZzMib1e9rZohs_FJg8MK52Ey494z40&index=7

///// Lecture 1: {
    - доступность
    - маштабируемость
}

///// Lecture 2: {
    - fat client: state is being saved on the client side
    pros: saving on traffic, delays, cache, constant connection, pushing (server sends events to client), offline mode, server without a state
    cons: update, different api versions, consistency, localization, experiments
    - thin client: state on server
    - session of user:
    authorization, coockies (id from server to client), memory on server, replication
    - fat web client: AJAX, Single Page Application
    - typical architecture:
    DB server
    Logic server
    Web Server 
    - resources: memory (structures to save data, access to memory), processor (blocks, system tasks, waiting, multythreading), disk, network
    - scaling: different servers, functions, sharding, partitioning, increasing quantity of replics
    - идемпотентность
    - RDBMS - ACID: atomicity, consistency, isolation, durability
    - optimizations: 
    index (disk operation are very costly and slow), 
    short transactions (one transaction waits another), 
    denormalization, 
    minimum logic, 
    minimum foreign key logic
    - CAP: consistency, availability, partition tolerance
    - master-slave: read from master and slave, write only to master, replication: sync, async
    - quorum
    - my read from master, others from slave
}

///// Lecture 4: Network stack {
    - 7 layers -> 4 layers
    Steps of HTTP request:
    1. DNS
    2. IP >> route => not in local network -> default gateway
    3. Route IP >> MAC == ARP Protocol
    - NIC: network interface controller. Configuring: ethtool
    - network stack is a huge program in OS
    - connection parameters:
    SO_KEEPALIVE
    SO_REUSEADDR
    SO_REUSEPORT
    TCP_CORK - данные пачками -> лучше througout
    TCP_NODELAY - as much faster as possible -> latency
    TCP_DEFER_ACCEP - don`t wake up until real data
    - get packet from NIC:
    user space network stack: DPDK, netmap
    XDP == express data path
    - RTT - round trip time
    - MTU == maximum transmission unit == 1500 bytes
    - MSS == payload

}
///// Lecture 5: balancing {
    - Master - Standby
    - FQDN == fully qualified domain name => Round-Robin DNS
    - L4 (TCP/UDP): balancing type (balancing of TCP connections) = LVS (linux virtual server):
    virtual ip address
    methods:
    1. assymetric routing: clint -> L4 balancer -> direct reply to client, bonding, lo == loopback. bond -> lo -> app on 80 port
    2. L2 == ipip == packet in packet to machine in other network, 1500 => fragmentation (+8-10 GB of memory),
    not works: path MTU discovery
    works: advmss(limit to 1480 bytes -> left space for 20 bytes [ipip])
    3. NAT == Network Address Translation:
    client -> balancer -> server -> balancer -> client
    load on balancer, huge configuration issues
    4. high availability:
    L4 Balancer [balancing & monitoring]: WRR (weighted round-robin, good to close connections - TCP aspect), WLC (weighted least connections), SH (Source Hash)
    5. upgrade/update: 
    6. Reliability: VRRP: two balancers or more (ping each other)
    7. Router: better to use source hash = ECMP == equal cost multipath 
    - DNS/GSLB (Global Server Load Balancing):
    TTL: time to leave = little TTL to check the server availability
    CDN == content delivery network:
    unicast: ip address prefix == ip network == ip address and mask => describe user -> cdn ===> from prefixes => go there
    anycast: 
    8. Load:
    To solve SYN flood:
    User-Space Network stack -> DPDK, Netmap, OpenLoad, pf_ring *100 speed 
    slow GET/POST:
    can overload tje server/sql server => proxy[nginx, HAProxy, squid, APACHE]
    solution: post of a huge file, proxy will accumulate an then throws it to server
    gzip BOMB (compress/decompress on the fly):
    solution: proxy of L7
}

///// Lecture 6: processor and memory {
    - von neuman architecture
    - harward architecture: bus of command and data
    - cpu: 
    non-conveyor architecture, 
    conveyor architecture (every element of the conveyor can work independently),
    superscalar (instrucion dispetcher)
    - caching: exclusive or not exclusive
    - CPU -> L1 -> L2 ->L3 -> RAM: if cache miss
    - external instruction set (MMX, AES)
    - multicore architecture
    - cache coherency => 
    paralellism:
    Symmetric multiprocessing or shared-memory multiprocessing[1] (SMP)
    NUMA
    - memory has size of 4kb pages, hugepages: 2Mb, 1Gb
    - processes work with virtual memory & swap
    - resources have to be at ratinal maximum
    stack
    mmap
    heap
    bss (uninitialized data)
    init data (initialized data)
    text (program code)
    - files: /proc/meminfo, /proc/<pid>/status, /proc/<pid>/maps, /proc/vmstat
    - utilities: free, top, ps, perf, numactl
    - VMA == virtual memory area
}

///// Lecture 7: data storage {
- parameters: volume, perfomance[normal, in degradation], latency, reliability, price
- HDD: low price, bigger volume | huge latency, power consumtion, not reliable on physical interference
- SSD: versus HDD -> block model of writing (read to buffer/delete/change/write)
TRIM sometimes has more priority then I/O operations
Garbage Collector: may clean all which is not necessary
Wear leveling: increase life of disks == balances degradation
Over provisioning:
- SATA/SCSI
- disk perfomance:
HDD: length of seek operations
SDD: paralellism
- disk elevators(schedulers) == change I/O operation conveyor to optimize those operations:
noop - FIFO (unite of one type requests)
deadline - trying to provide specified latency, two queues on read/write
cfg - as evenly as possible
bfq - based on cfg, but more optimally
- disk state: SMART std 
- partitions: MBR/GPT
- inode == index descriptor
- fs: journaling, directories
- RAID
}

///// Lecture 15: modern data structures {
    - streaming nature of data processing, no random access, uncontrollable incoming rate
    - solution: small data structures, more smaller - less accurate, ubiquitous hashing
    count-distinct (how many different items in dataset):
    classic == sort and run == used almost in all DB, spark approxCount Distinct, allmost all DB
    ~ linear counting => reduces memory used => database query optimizations
    BitSet mask = new BitSet(m)
    int position = hash(value)
    mask.set(position)
    ~ LogLog Counter(how many different item sin dataset):
    provide hash in binary == strings of 1010101 => binary division by  rang
    ~ count-min sketch(how often element appears in dataset):
    generic == multiset, hashmap, values + counters
    minimum on results of hash function(sometimes we have conflicts)
    depth x width
    use: picking safe password, natural language processing, heavy hitters identifying
    ~ find top-k element in dataset
    ~ space-saving:
    content-delivery networks, traffic monitoring, anomaly detection
    count-min sketch + heap
    ~ membership (does element belongs to dataset):
    generic: set/array =? O(n)
    Bloom Filter used:
    use: reducing exact checks/lookups, widly used in DB, prevent one-hit-wonders from caching,
    avoid show already shown items to user
    ~ sliding window
}