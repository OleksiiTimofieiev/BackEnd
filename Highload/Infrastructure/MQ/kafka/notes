https://www.youtube.com/watch?v=-AZOi3kP9Js

- distributed event broker
- CAP: in accordance with CA parts
- horizontal scaling
- message logic: events -> broker(broadcasting) -> consumers
- broker: receive/store messages for consumer; usually several united in Kafka cluster;
- zookeeper (db): to store coordination and state of the cluster (metadata, state, cluster configuration, topics, partitions)
- kafka controller: master for replication purposes; for data consistency
- message: 
key: optional, used for distribution via cluster
value (array of bytes)
timestamp (unix)
headers (attributes)
- topic: stream of data, FIFO; each consumer data from its own topic
- partitions: FIFO; each broker may have its own partition; sometimes topics have to be managed manually;
- deletion: in accordance with TTL(time-to-leave); segment to be deleted; check future timestamps as a possible cause why deleteion not happens;
- data replication: replication-factor(>1); one replica is being leader replica;
kafka-controller selects leader; R/W only with leader replica; follower is being idle; follower poll leader for changes -> solution: ISR follower with sync write,
ISR follower can be used as leader, min.insync.replicas = 3 => -1 from node to not block R/W operations
- producer: send message, acks (receive guarantee):
0 - no confiramtion needed
1 - confiramtion only from leader replica
-1==all - confirmation from all insync=ISR replicas

1. fetch metadata(checkout leader, metadata from zookeper) -> blockes send until receives information from zookeper;
2. serialize message:
key.serializer
value.serializer
StringSerializer
3. define partition:
explicit partition
round-robin
key-defined (key_hash % n)
4. compress message
5. accumulate batch (batch.size, linger.ms == timeout)

- consumer: poll messages
1. fetch metadata
2. poll data from leaders

- consumer group: each consumer reads its own partition; kinda microservices logic;
- offset: topic __consumer_offsets => to keep metadata on messages have been already read
- commit types: 
auto (at most once -> miss messages)
manual commit (at least once -> duplicate messages)
exactly once (not missed, no duplicates)




https://habr.com/ru/companies/otus/articles/725168/

- better to use JSON in messages
- topic is being used for message grouping
- uses FIFO

https://www.youtube.com/watch?v=BtmYjTO1EpI&list=PPSV

- message broker for big data
- more reliable then rabbitMq ?
- producer -> broker -> consumer [zookeeper]
- topic: array list
- replication: master slave, write only to leader, async delivered to slave
- master may die, and leader will be chosen -> async replication == some loss of data,
clean || unclean leader election
data will always be lost
leader even may be chosen if all is ok
- leader change without a loss:
request.required.acks = 1
request.required.acks = -1 => successfull write to all specific partitions
min.insync.replicas.per.topic = 2
some small overhead of producer,
way out:
incync.replicas = 2
replication factor = 3
- offset:
earliest - latest
how to save offset is main for the consumer
at least once
exactly once -> to save data in offsets in kafka atomically
- not always correctly distrubetes nodes
- better to monitor:
disks, network, scaling, leader selection, partition deferred, response time

-------

ðŸº  /opt/homebrew/Cellar/zookeeper/3.8.1: 1,103 files, 45.5MB
==> Installing kafka
==> Pouring kafka--3.4.0.arm64_ventura.bottle.tar.gz
==> Caveats
To restart kafka after an upgrade:
  brew services restart kafka
Or, if you don't want/need a background service you can just run:
  /opt/homebrew/opt/kafka/bin/kafka-server-start /opt/homebrew/etc/kafka/server.properties
==> Summary
ðŸº  /opt/homebrew/Cellar/kafka/3.4.0: 203 files, 101.5MB
==> Running `brew cleanup kafka`...
Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.
Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).
==> Caveats
==> kafka
To restart kafka after an upgrade:
  brew services restart kafka
Or, if you don't want/need a background service you can just run:
  /opt/homebrew/opt/kafka/bin/kafka-server-start /opt/homebrew/etc/kafka/server.properties